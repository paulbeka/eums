{
    "videoTitle": "The world's first AI regulation - Interview with the European Commission AI-Office",
    "videoId": "P_8Jkm4_I2g",
    "transcription": "e hello ladies and gentlemen let me see we should be live I'm going to check the uh live stream for a bit to see if we are actually live people can hear me if the audio quality is good uh it looks like yes as I can see okay wonderful um so ladies and gentlemen today we have a very special uh live stream for you guys we have a interview uh on the AI act and many of you might not even know what the AI Act is yet um but promise we'll dive into that fully um we're going to be covering it with two very special guests um first with um Irina or and um I announced earlier that we would do it with Thomas reier as well um however he was not available but no threat we have an equally as impressive guest Laura yugul um they both have worked directly on the ai ai act and are leading experts in this field um and we are going to be discussing anything about this so make sure that you have your questions ready as always um follow us on all of our social medias um we have our Instagram Pages uh we have X and we have everything so make sure to follow us there and um yeah without further Ado I feel like we should uh switch to our guests um and here we go hello Laura hello enina you're on screen hello hi happy to be here yeah wonderful to meet you guys um especially on such late notes as well Laura um I I appreciate it fully and I think we all I can speak for everyone that we really appreciate it um so I think we can just go very uh very basic for people that are uninitiated um what is in short um let's say the elevator pitch for the AI Act what is the biggest policy contribution that this act tries to do and I'm going to ask that to but if you if you guys decide the other can answer better then please feel free to do so okay then I start with what is the AI act um the AI Act is a law and it is trying to regulate AI in Europe so the type of AI which is um being now it's a technical term being put in the European market which is being used there we don't regulate all AI but we take an approach where we only regulate where we see a very specific risk okay and um so this is perhaps 15% of all AI systems which are regulated and all the rest are not regulated and they are most most of them have to follow some rules and very few ones will be prohibited and then to L for the rest and what we try to achieve with the AI Act is to make sure that AI That's developed and used in Europe is safe and is trustworthy and we can rely on our rights and freedoms being protected on the AI being uh safe and ensuring that when it is used um and we interacting with it um our health uh is protected and our safety okay so if I understand it correctly it is only for a let's say more specific smaller portion of AI usage uh really aimed in at the the higher risk uh areas of AI um so could you dive a bit into the the history let's say the um how did this act came to be what was the first push because this is a very obviously new area um I was surprised that the European Union was so quick with addressing this this um new uh topic let's say so could you say a bit more about that actually we were even much earlier we have already since the early 2000s been supporting AI in particular in terms of research and Robotics and things and then the topic became more and more political there were more and more fears and discussions and um so that was the moment when we the European commission thought okay now we also need to do something and so in 2018 we had a first strategy on AI with that strategy we had three pillars so we were looking into the economy the competitiveness The Innovation like how can we bring Europe in terms of AI forward then the second pillar was the question of social economic effect so what is the impact on work what is the work of the future and the third pillar was ethical and legal question and ever since then we have pursuing also these three pillars so it's not that we are only regulating but we are doing also plenty of other things but so this was 2018 and on that basis then when it comes to ethics and legal we were making a call for a what we call high level expert group um so real experts who could tell us about the ethics of trustworthy artificial intelligence and um we got then a report um we got um principles we got guidelines we got an internet based tool from them and then our new to be president fer Lon five years ago decided that ethics is important but that she believed that also part of it needed to be regulated y so that was summer 2019 and then we did like Yeah from there it had started all right so it was really it was already in 2018 I I remember reading that this was a discussion can I say was it a proposal in 2020 that was handed in um officially or by the commission to or was that later or earlier I'm not quite sure about the timeline was it 2020 in 2020 we had um a so-called white paper right right and since our procedure is to consult with everybody so there we put forward our ideas for regulation how could that look like but we put also again forward our ideas for excellence how we can increase Europe's competitiveness in this white paper and that was broadly consulted and that was the basis for the AI act where the commission proposal got out in April 21 okay right all right so um you mentioned a few pillars there and I would like to go into them uh one by one a bit later especially one um where I guess a lot of I want to say criticism has maybe uh come lots of people are worried for the um let's say economic aspect of such an act but we'll get into that a little later um for now I think it is very important to ask for I believe everyone watching um H How would how will this impact the average EU citizen what is why should I care as a u EU citizen um for example um or maybe they shouldn't go ahead I think um what the EU um AI act will bring to EU citizens are three things it's um trust in AI its rights in regards to Ai and remedies when it comes to trust we we've already talked about it we are looking at AI applications that can pose risk to health to safety to our freedoms and in the future we can trust that those AI systems um this could be for example an AI That's used in your University to evaluate your exams it could be an AI that um an authority uses to see if citizen should get social benefits or not it could be an AI that your energy provider uses to detect failures in the network um that they are safe um and that they comply with certain requirements that make sure they are trustworthy so that they have been for example trained to have as little bias as possible so that there are measures in place to make sure they are safe against cyber attacks um that there's always a human having the last oversight over anything that happens that decision made by this AI are explainable um so this is the component of trust and that is really important the second one is um I mentioned rights uh going forward there will be a right to ask for explanations there will be possibilities to complain if you feel your rights have been um impeded by an AI or the way that this AI has been used and then finally there are also remedies there are possibility for class actions there is protection for whistleblowers so this is why the AI act will tremendously benefit citizens going forward um particular this element of trust okay so if I'm summarizing you correctly it sounds like um me as the average EU citizen let's just say that um we are getting a bit more protection a bit more uh like a shield so to say against unregulated AI in says that we have some rights that we could afford ourselves instead of having nothing at all is that a accurate representation or am I understanding it wrong very good summary okay of the situation yes there will be generally a higher level of protection for your rights and for your safety in um relation to AI okay so I I imagine obviously with with any regulation or act um you are going to have to um implement this obviously uh the the innov themselves but also the um deployers of AI I believe they're called people that use the AI in their systems um let's say something goes wrong uh one of the like in I believe it's it takes two year or like in two years they have to implement this or or a year one of the two I thought I read um where uh the higher risks have to go earlier the the the low risks can can be a little later with implementing it um however what if something goes wrong someone a a company um or an innovator doesn't apply these rules um how is the EU going to check these companies um in either uh oversight or make sure that they are actually implementing your the changes the ACT um tries to you know uh Implement right so of course you are touching on a very good point no rules um have effect if they are not enforced if they are not being complied with and for what concerns the AI act most of the rules there will be um Market surveyance authorities in the member states keeping this oversight making sure that the rules are checked um going forward before any AI system that is high risk um can be put on the market there needs to be a compliance check and then those who put them on the market they have responsibilities they need to monitor for incidents they need to to some extent report or Flack um to these authorities and whenever there's an incident happening the authorities have rights to ask that this AI system is temporarily removed from the market for example that measures are taken to make sure it complies with the AI act and then that is the rule in principle but we all know that there are extremely powerful AI models and they are also regulated in the AI to some extent um the most well-known examples are the large language models that are on the basis of generative AI systems um that are increasingly present on the market jgpt being the best example for that um these models there's only a handful of companies who can put them on the market and so it was decided that it's important to centralize the oversight on EU level and we have established an AI office on EU level it's a European AI office at CN Brussels in the commission and um this AI office will oversee that um they also comply with the rules um will have the possibility to evaluate these models to check them for risks and to take measures if maybe in an ideal case this doesn't need to be but we all know um that we need to prepare for the possibility okay yeah ARA do you want to add anything to that or no I think it was a perfect reply okay so um let's let's move on to the next topic then I what I'm hearing is a lot of almost positive things and which is natural of course for someone who is working on the policy to be positive about it um I even though it may be painful I want to look at more of the maybe potential downsides of it as well I think the biggest question and thank you everyone in in the live chat people are worried about is that um we hear these news articles talking always about the EU is falling behind in Tech Innovation the EU is um you know behind the the tech Giants of the United States um we are not competitive enough etc etc um I want to delve into that topic specifically because there there are or at least from my perspective uh there might be some some downsides and you might you guys might know a lot more about that than I do however um there was a interesting paper research or consultation grounded it was two years ago um but it showed that even implementing such the such an act would be between one one and 2.7% of a of a small to medium uh Enterprises uh Revenue um or things like arguments people use are red tape you know the deployment and the development of AI is going to be slower so why should they should these companies do it in the EU and not just go to the US um so I I guess at first I would like to hear your thoughts on this uh on this more negative side on the a AI act or what risks it might bring um no they I think um there are several aspects to it so first of all as I said in the beginning it does not regulate all systems it's far from it it really only regulates the system where there is a high risk to fundamental rights to safety and to health second of all we don't believe that the costs are at the end going to be that High um because first of all the requirs we are having they I think pretty logical to some extent so if you are a decent person you will think of them the one or the other way you will anyway look into cyber security you any way want your system to be accurate because otherwise it will not perform well on the market and um if you have too much bias too much decisions too many decisions that discriminate against people um at the end you will have liability questions with or without AI act um so I think a lot of it is really common sense but most importantly what we are going to do and I think this is an advantage is that these requirements they will be subject to standardization which means that they will it will be relatively easy to apply them to think them really from the early design phases so I don't think um that it's going to be that bad um as we frequently hear um and then I just said like if there is a problem you have a liability issue but what we should never forget in countries like in places like the US um they don't like to regulate before but if something goes wrong the liability you have to pay is tremendous um so which means that there is also like you balance it we regulate more before but if it goes wrong there you have to pay a lot afterwards and then about companies going to other places um you know the AI act applies to all AI system getting on the European market which means that also if a company from the US or from elsewhere wants to use a system or the results of a system or wants to sell it in Europe the requirements need to be complied with um which means that if you want to go to another place you need to be pretty sure that you really really want to miss out on these um Europeans which are still like we still have a lot of money and we buy plenty of things um there is another aspect to it and this is something which is part of our Excellence is indeed that also it is more difficult for startups frequently in Europe because just here the financing structures for startups but in particular for scale ups are different so once I'm in a certain phase of development it's much more difficult but this is something about European mentality um and this is a different story from the AI act yeah okay thank you um I guess that almost ties into a question from the live chat uh someone asked um if the ACT treats all companies the same way or is there any differentiation between sizes uh as in maybe implementation time um let's say maybe even possible fines um or is it all it's all the same it's all the same standard near you want to start so in principle um when you have an AI system whether it poses risks it's not a question of who's the company behind it it could be a startup developing an AI that is really discriminatory in the same way um also the other way around but we of course acknowledge that smmes are the backbone of the European industry and we want to support them so the rules they will um apply regardless of the size of the company but we will put in place certain measures um for example there are a couple of simplifications for smaller companies um when it comes to Quality Management or reporting uh just taking into account that certain things are just not as feasible for them um we will also of course take the size of the company or not we but in case um and that's really a last resort but in case enforcement measures need to be taken that will be taken into account um and we put in place certain regulatory instruments with which we hope we can particularly support um smaller companies in their journey to putting an AI on the market that complies with the AI act one example for that so-called AI regulatory sandboxes it's um it's a instrument whereby there's a controlled environment where smes or other innovators can work together with authorities to develop an compliant product and and accompanied along the way so we are focusing um on smmes on making this um as little burdensome as possible on them but in principle the rules apply um no matter the size of the company okay understood um Jen maybe a a bit a bit more broadly um I guess if I'm going going to be asking questions if something should happen um it's your private opinion so and I'm in no I'm in no um false pretenses here that this is the EU commission's opinion but um I think a bit big large of the issues people have or maybe the worries is that um they would like to see some sort of invest investment maybe some sort of push from the from the European commission into um really blossoming or push propping up the EU Tech businesses like but also things like chip industry um areas like that and I I I guess I wanted to ask should in your opinion the EU commission do something more for that um are they doing enough already where do you see the the pitfalls here because um for some reason there exists quite a bit of of worry amongst European citizens that this is not all Rosy and bloomy right H well the question whether we could be doing more I prefer not to reply to but I can tell you what we are doing and that that is really a lot so it starts with the credle it starts with research um where we are financing plenty of projects and ideas and research centers and exchanges really um for AI to be developed in Europe um then after the research the next step is indeed the testing so um um we are providing facilities that the developers can really test under different circumstances also under real circumstances the AI to see whether this is um good for a market or whatever it is it must not be a market AI um and from the testing then laa was already talking about the scent boxes here we have also the link to the AI act um we provide the facilities the possibilities to help to make sure that also what has been research what has been tested is compliant with the rules um so this is one thing then indeed and that I already mentioned we have the question of funding and there we are giving incentives also for other financiers to step in um so we are trying to do things um I think we're doing a lot ined I said it before there's also something about the mentality of investment and we know know and that is not only a problem with AI that there Europe is in some countries still very much like um more attached to the established companies and the ones they can already trust and we are not exactly the heroes of taking a risk in investment um so this is something um and it depends indeed um where you come from um um there are some member states where it's much better but there are also others where it is uh um where there is still some margin for development okay um once you have this sorry I just I I I would just quickly continue with what we're doing the next step then which is an interesting one is the European digital Innovation Hub so no a company doing something completely different can go to such a hub to get help with the question like what kind of AI can I use for my company so also to get like what has been developed together with the companies which then can get tailor Med Solutions of AI which will help them right so this this about the hubs um and I think all this together which really covers the value chain um um is is a very um successful concept um and indeed it always needs to be further developed further ftuned and um we all know that we all can need more money for certain tasks um but I think in general it's fine okay okay um Laura I would I would ask you almost the same question um because I'm I'm I'm wondering um maybe you have a better idea of it why is it that then people see the the this AI act as the the first their first in instinct is that it it harms Innovation or it um it stops it like it's harmful in some way because um the EU has a maybe an image I could be wrong but at least in my eyes of wanting to regulate first um and then seeing afterwards with the many like the the many digital X stuff like that so why is that then the the case that people is are immediately thinking of this and could the the commission or any any Organization for that matter help in I guess is it a is it a problem of identity image anything I guess I guess your take on on any of that many questions in one um I would say so in has been talking about the journey we've had until we've reached now the AI act being in forc the first rules soon applying the perception has really tremendously changed in in my personal view we've we've had this feedback for a long time and then end of 2020 CH GPT was released and it started this Avalanche of generative AI systems and all of a sudden um AI became present in the lives of many many more people than it had been before or visible at least AI in in many things that were used on a daily basis without even even being aware of it but AI has become a topic of discussion and and since then um it's my view that or or impression um that the risks have also been much more visible and and understood and I don't or the the feeling is that many citizens Now understand why it may make sense to put in place guard rails then how far should these go um where's the balance between too many rules and and uh too little Innovation or or impeding on Innovation that's of course something you can always discuss um but the question of if um my my impression is that everyone agrees that we need some guard R and then if you look across the pond for example in the US um regulation of AI is the topic of discussion right now if you've been following the news uh over the last week California they are putting forward um some pretty serious u rules on in particular on these very powerful large language models and um there have been CEOs of big tech companies taking sides whether they find this law is going too far or whether it's um the needed minimum that needs to be put in place um to ensure that risks are are addressed um so it's also a matter of perspective um so I I do hope that um the advantages can be seen um and of course it's maybe also a matter of personal um views on where the balance lies between too much regulation and and or too little um we also hear the contrary um we from from different perspectives there are copyright holders for example who think the AI act should have gone further in in making sure that their um works the images the photos they put out in the web cannot be scraped and used to train um generative AI that then replaces their artistic uh jobs so you know it's it's have perspective and I I believe it's with almost any piece of legislation that um you you can never make everyone happy um there's always going to be some weighing uh to be done and some decisions that have to be made so I I understand that fully um I want to turn to the to the do the chat for a second because someone really wants me to ask a specific question um and I my knowledge on this topic is a bit limited so to say so I I hope you understand the question um Elliot please ask will the EU make sure we can get access to Future open- Source AI models by meta since meta said that they will not uh be releasing them due to uncertain regulatory environment I think we can give a short reply but this is indeed not what we are doing this is not subject to the AI act um so what we could do is tell um tell um people how that model should look like and and if there is a problem we could ask for the model and things um but um the whole thing is a puzzle so we have um plenty of uh legislation in the digital field and not only in the digital field and there we have the Digital Services act we have the digital Market act we have competition law which means that under certain circumstances um companies are being required a certain transparency now it always depends on the individual case um so I cannot tell you like we are going to enure this or at least I'm not aware perhaps um this is happening somewhere and perhaps Laura knows more um but like there are certain tools to ensure that there is transparency and that Gatekeepers so if there are models really important cannot be Gatekeepers but that they need to open up up okay yeah that makes sense and and if I can complement so under the AI act in fact um we introduce rules for those most powerful models we talked about it but there is an exception for those most powerful models that are been put or released on the market for in open source so for them the rules will not apply because what we are putting in place are rules to make sure they are more transparent about the way that the model has been trained but if if it's open source of course this transparency is granted it's already there yeah um so another rather technical question uh but it might apply a bit to more of the Practical applications um someone asks if I use open AI API to one of my um to one of my features in my saas application am I a Dev am I a deployer or a provider of AI I I I don't know what that question really means once again my knowledge is limited on that front but maybe you you have a bit more insight on that wait if I use the APA I for the saas application um I'm I'm struggling um on the sa I what I can say is so for for everyone we have these two concepts of provider and deployer yes yes exactly in the AI act so providers are those who put an AI system on the market or a general purpose AI model general purpose a model that's the terminology of the AI act for those most powerful models SL language models Foundation models um it's a general term to cover those models um and then we have deployers of AI systems those are the public authorities or the companies uh let's say company that buys an HR tool that's AI based to process CVS those are deployers of AI systems um when it comes to AI systems we have rules that will apply to both providers and deployers so those who place them on the market those are the high-risk ones for example they need to do the Conformity checks and so on and those who put them then into use um those high-risk AI systems the company that's using the HR tool I was talking about they need to do certain obligations as well when it comes to the models we put in place rules only for the developers um and um there of of course there's a fine line um when you have a model that's provided for an API whether this is still a model or whether this is already an AI system um model is a component to the system and um therefore what is built on that model uh defines then whether or not um it's still a model or not and and then if you take one of these models and build something on top um from which point onwards are you considered a provider yeah we have been trying to provide answers um but of course this is always difficult to do in the law itself because it needs to be abstract and general and future proof but uh here we Tred to provide more guidance on this in in the recites that explain why which rule has been put in place and right now we have a process going on whereby we are detailing these rules in the code of practice in which um a first group of stakeholders including developers of these models is coming together to um really develop how um what it means for example when we ask to do technical documentation how this should be or could be reasonably done and within this code of practice we are also expecting that there will be a discussion around um where is the borderline between something still being a model and something already being a system and from which point onwards after having done fine tuning do I become a provider myself um so in this regard for the guidance is is under preparation and I hope that the recycles or that in the future this will answer um your question yeah okay thank you um a part of um the what it feels like is this guideline is very um let's say aimed at just the regular way of how it should something should go like just the general procedure but um late lately or maybe not so lately we have seen a uptick or a rise in malicious use of artificial intelligence or um maybe algorithms that aren't exactly created in uh in good faith a a user asks this as well um how could the um the European commission handle Ai and algorithms that aren't designed in good faith um as deliberately promoting for example more radical views um things like um I guess an example which might not be the perfect example is the algorithms for on social media that have a tendency to push people into Echo Chambers uh therefore promoting maybe more radical views or even so that these more get more traction or more interaction because they are so radical and therefore um maybe even harming certain systems is there a part or has there been has this been part of the discussions about the AI act or is this something that is a bit outside of that scope both um so it is partly covered by the AI act but partly as I said before there is also other legislation y but like when it comes to the AI ACT first of all we also have a few prohibitions and these prohibitions um um are also forbid manipulative practices and certain also manipulative influencing practices with regard to vulnerable people um so this is something so like if you are really in the super bad category um it will be prohibited of course but um I I assume that within the details um it is or at least thought of what a vulnerable person is right or what a um manipulative Act practice is because obviously you can debate on the the terminology there right um what we're going to do these are the first rules to enter into force in February next year and right now we are intensively working on providing guidance and there exactly we do want to Define all this um so we want to make very clear what is covered by this prohibition what is not covered we want to give many practical examples yeah um that really it's also clear like this is in this is out and um before adopting before publishing this guidance it will also be consulted okay so sometimes this automate will be consulted and what we are in particular hoping for is that then people also come with their use cases like if somebody does this to me or also if I want to do this is this prohibited or not sure yeah this is one part and just quickly on a second under the AI act um that in particular relates to AI generated content but we all know that we have a lot of issues with deep fakes with um other things there we are going to have transparency requirements so we have a labeling but we also have a water marking um that at least this is not all we're having we're having other rules but at least again we are back to the issue of trust that people can much more easy say okay this comes from this Source or I just see this is something um which has been generated um so that it at least partially already simplifies our lives on that okay uh yeah thank you um as we are nearing the the closure of of our interview I would like to look a bit more towards the future and towards the chat um if you have any more pressing questions please ask them now um the super chats get a priority so if you have anything that you really want to ask uh be sure to share it with us um I want to let's say move a bit to the Future so um how do you expect that this um AI Act is evolved because I've been reading everywhere that it is supposed to or tries to be at least as future proof as you can possibly be um in in what sense or how future proof you can uh probably never be 100% future proof anyways um what do you think of the F Effectiveness would it reach its goals um where do you see it going in the in let's say five years somewh that yeah um maybe I can start with one expectation that I have um was something that we we already partially observed that if been talking about the us earlier and the discussion of Regulation there they are not the only ones um since since generative AI has become such a big topic since it's been so much more in the public eye we've seen um a lot of international activity a lot of discussion about regulation um we now have a new UK government and in their speech saying well when they introduced themselves they also announced that they would be doing legislation on AI and and we are really the first in Europe to come forward with um a horizontal comprehensive regulation on AI and this risk-based approach that we've taken we see that it's becoming sort of a blueprint for the thinking of other International Partners so one big effect that I personally expect is that we will see see regulation all over the world that's following a bit not every aspect but at least some of the core principles um okay yeah effect is is the term that's often used in reference to that they had the Brussels effect right where uh where others copy copy us in a certain way okay inen do you have any expectations do you think the goals or um it will be effective anything along the sort along those lines um yes I think it will be effective um and um this is really also but the question we had already discussed and laa had already said like um um that in the beginning everybody was like why are you regulating and you're like um you're really hampering Innovation and um one of the most interesting days in my life was when we received all of a sudden a letter um signed by plenty of companies asking us for regulation interesting um so I really believe that where there is a high risk um it will set standards and um it will really um help to avoid certain AI systems being put on the market and I think that this will be particularly relevant um Al particularly important when it comes to discrimination and bias um not only because the AI Act is there but also because like in the countries like the Netherlands or Denmark or Austria there were some not so nice experiences with such systems with yes some results which were a bit doubtful and that also then people saw like okay it's good to regulate and also saw certain dangers and I think with our requirements on data and with these experiences I think yes yeah last sentence if I may to the Future in one year's time we will already make a first evaluation whether the com prohibitions we have in the AI act and whether those AI systems we classify as high risk so those that are subject to most of the rules whether that is still up to date whether there's need for an amendment so we are taking the future proofness serious and there are many mechanisms like that um to make sure that what we have in place um will still be valid in a couple of years time okay uh very good I'm going to ask one final question um and it is a bit um more on the I think the outlaw so the unacceptable risk category um someone is wondering um if the uh EU or the European commission is going to ban regulate real-time face uh facial recognition in the AI act and I believe it is already said that uh systems like social credit scoring um is is is out roud out loud not allowed but maybe a bit more on um realtime facial recog Ah that's my favorite um now we cannot say it in a nice way so real time remote biometric identification that includes face recognition for the purpose of law enforcement in publicly accessible spaces o is going to be prohibited okay from the second of February there are a few exceptions to it but really when it um when it gets bad like in terms of terrorism serious crime or missing person then there are certain exceptions but you need to have an authorization before to use the systems but all the rest of it in real time would be then prohibited thank you very clear uh yeah thank you so I believe that um that is most of our time today um I want to first thank of course the lovely guests for joining and sharing your expertise and of course the audience as well thank thank you very much for all your interesting questions um I would like to give the last words to to both you Laura and Arena do you want to share anything you want to say anything any last wishes any good fortune please go ahead and if not then I I can do one thing I I heard you opening saying um asking to follow um of course we support that everyone should follow you um but we we also try to actively communicate about what we do in the AI office um what are the next steps when it comes to the AI act um and that we do on very different channels from our commission homepage to LinkedIn um but the European commission is also active on other social media so make sure to check that out um and thank you very much for the attention thank you for inviting us and yet yeah if I might just add to that sorry um um one of the channels we are also communicating with is the called AI Alliance and I find this is pretty unique so we have more than 4,000 stakeholders we have companies we have citizens we have NOS we have Academia so it's really everybody who becomes a member to discuss certain topics we will be also more act more actively working with the aines where people can discuss where people can post and um in that context I said it before we will be publishing also um documents for stakeholder consultation like on the prohibitions and we are really grateful for input of course yeah no so um we will make sure to link all of those um websites and pages in in our description below afterwards so that people may find them and um if if that is all then um I want to thank everyone once again and I will um or actually um One Last Thing Before I before I leave Sunday we're going to have a nice interesting live stream as well it's be about the German um bundeslander election so please make sure to stay tuned for that but without further ad thank you all for watching and I'll see you in the next live stream"
}